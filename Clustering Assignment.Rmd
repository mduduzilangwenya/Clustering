---
title: "Clustering Assignment#4"
author: "Ran Dou, Mduduzi Langwenya, Kimo Li, Siyan Lin, Muhammad Furqan Shaikh, Tianyi Zhou"
date: "04/02/2019"
output: html_document
---

load all libraries
```{r, message=FALSE, warning=FALSE}
rm(list = ls())
library(cluster)
library(tidyverse)
library(NbClust)
library(factoextra)
library(clValid)
library(writexl)
library(corrplot)
library(pROC)
library(leaps)
library(car)
library(forecast)
library(knitr)
library(caret)
```

### I. Data cleaning and impution

##### Data importing
```{r, warning=FALSE, message=FALSE}
###import the raw diabetes data
diabetes <- read_csv("diabetes.csv")
###delete all the missing valuse
diabetes1 <- diabetes %>%
  filter( Glucose !=0 & BMI != 0 & BloodPressure != 0 & Insulin != 0 & SkinThickness != 0) %>%
  dplyr::select(Glucose, Insulin, Outcome, BMI, SkinThickness )
```

##### Fill-in Zero Value
###### 1) Insulin
```{r,message=FALSE,  echo=T, results='hide'}
### Insulin 
# stepwise for choosing models for Insulin 
insu.lm.null <- lm(Insulin~1, data = diabetes1)
insu.lm <- lm(Insulin~., data = diabetes1)
insu.lm.step_both <- step(insu.lm, direction = "both")
sum_both <- summary(insu.lm.step_both)
### create the model for imputing Insulin missing values
lm.data <- lm (Insulin ~ Glucose + BMI, data=diabetes1)
pred.1 <- predict (lm.data, diabetes1)
impute <-function(a, a.impute){
         ifelse(a$Insulin == 0, round(a.impute, 0), a$Insulin)
}
diabetes$newInsu <- impute(diabetes, pred.1)
rm( insu.lm, insu.lm.null, insu.lm.step_both, sum_both, lm.data)
```

###### 2) Skinthickness 
```{r}
### stepwise for choosing models for Insulin 
skin.lm.null <- lm(SkinThickness~1, data = diabetes1)
skin.lm <- lm(SkinThickness~., data = diabetes1)
skin.lm.step_both <- step(skin.lm, direction = "both")
sum_both_skin <- summary(skin.lm.step_both)
### create the model for imputing SkinThickness missing values
lm2.data <- lm(SkinThickness ~ BMI, data=diabetes1)
pred.2 <- predict (lm2.data, diabetes1)
impute <-function(a, a.impute){
  ifelse(a$SkinThickness == 0, round(a.impute, 0), a$SkinThickness)
}
diabetes$newSkin <- impute(diabetes, pred.2)

rm(skin.lm.null, skin.lm, skin.lm.step_both, sum_both_skin, lm2.data, pred.2,diabetes1, impute, pred.1)

diabetes$SkinThickness <- NULL
diabetes$Insulin <- NULL

diabetes <- diabetes %>%
  dplyr::rename(Insulin = "newInsu",
         SkinThickness = "newSkin")

diabetes<- as_tibble(diabetes)
diabetes.copy<-diabetes
```

#######################################################################################

### 1. K-Means Clustering

1. Scaling 
```{r}

diabetes_kmeans <- diabetes
# ==========
dia.df.num = model.matrix(~ Pregnancies + Glucose + BMI + DiabetesPedigreeFunction +
                            Age + BloodPressure + SkinThickness + Insulin 
                            ,  data = diabetes_kmeans)
scaled_data = scale(dia.df.num[,-1])
```

2. Choose Number of Clusters- Use Within Sum of Squares (wss)
```{r}
## How many clusters to choose?
## ============================
k.max <- 15
wss <- sapply(1:k.max, 
              function(k){kmeans(diabetes_kmeans$Glucose, k, nstart=50,iter.max = 20 )$tot.withinss})
wss

plot(1:k.max, wss,
     type="b", pch = 19, frame = FALSE, 
     xlab="Number of clusters K",
     ylab="Total within-clusters sum of squares")
```

3. K-Means Clustering - I chose 3 Groups
```{r}

# Find 2  groups
# ==========        # because starting assignments are random
dia.k2 <- kmeans(diabetes_kmeans , centers=2, nstart = 50, iter.max = 20 )

#add cluster back to dataframe
diabetes_kmeans$cluster <- dia.k2$cluster

#rename levels 
diabetes_kmeans$cluster <- gsub(1, 0, diabetes_kmeans$cluster,ignore.case=T)
diabetes_kmeans$cluster <- gsub(2, 1, diabetes_kmeans$cluster,ignore.case=T)

#change data types
diabetes_kmeans$cluster <- as.factor(diabetes_kmeans$cluster)
diabetes_kmeans$Outcome <- as.factor(diabetes_kmeans$Outcome)


library(caret)
confusionMatrix(diabetes_kmeans$Outcome, diabetes_kmeans$cluster,positive = "1")

```

# plotting 
```{r}
#plot glucose and BMI
ggplot(diabetes_kmeans, aes(Insulin, Insulin, col = factor(cluster))) + 
  geom_point(stat = "identity")
```

```{r}
#plot glucose and pregnancies
ggplot(diabetes_kmeans, aes(Glucose, Insulin, col = factor(cluster))) + 
  geom_point(stat = "identity")
```

```{r}
#plot blood pressue and insulin
ggplot(diabetes_kmeans, aes(BloodPressure, Insulin, col = factor(cluster))) + 
  geom_point(stat = "identity")
```

```{r}
#plot  Age and insulin
ggplot(diabetes_kmeans, aes(Age, Insulin, col = factor(cluster))) + 
  geom_point(stat = "identity")
```

```{r}
#plot BMI and insulin
ggplot(diabetes_kmeans, aes(BMI, Insulin, col = factor(cluster))) + 
  geom_point(stat = "identity")
```


#######################################################################################

### 2. Hcluster
```{r}
diabetes_hclust <-diabetes.copy
# delete outcome. take glucose as target
diabetes_hclust <- diabetes_hclust%>% dplyr::select(-"Outcome")

# normalize input variables
diabetes_hclust.df.norm <- as.data.frame(sapply(diabetes_hclust, scale))

#diabetes_hclust.df.norm$Outcome <- diabetes_hclust.copy$Outcome

# add row names: 
row.names(diabetes_hclust.df.norm) <- row.names(diabetes_hclust) 
dhclust.norm <- dist(diabetes_hclust.df.norm, method = "euclidean")  

# in hclust() set argument method =  
# to "ward.D", "single", "complete", "average", "median", or "centroid",  246 work
hc1 <- hclust(dhclust.norm, method = "single")
plot(hc1, main = "Single Linkage Clustering", hang = -1, labels=FALSE)

hc2 <- hclust(dhclust.norm, method = "average")
plot(hc2, main = "Average Linkage Clustering", hang = -1, labels=FALSE)

hc3 <- hclust(dhclust.norm, method = "median")
plot(hc3, main = "Median Linkage Clustering", hang = -1, labels=FALSE)

hc4 <- hclust(dhclust.norm, method = "complete")
plot(hc4, main = "Complete Linkage Clustering", hang = -1, labels=FALSE)

hc5 <- hclust(dhclust.norm, method = "centroid")
plot(hc5, main = "Centroid Linkage Clustering", hang = -1, labels=FALSE)

hc6 <- hclust(dhclust.norm, method = "ward.D")
plot(hc6, main = "Ward.D Linkage Clustering", hang = -1, labels=FALSE)
```
###compare and choose best clustering model with linkage and k
```{r}
single=rep(0,6)
for (i in 1:15)
{memb1<-cutree(hc1,k=i)
single[i]=dunn(d.norm,memb1)}

average=rep(0,6)
for (i in 1:15)
{memb2<-cutree(hc2,k=i)
average[i]=dunn(d.norm,memb2)}

median=rep(0,6)
for (i in 1:15)
{memb3<-cutree(hc3,k=i)
median[i]=dunn(d.norm,memb3)}

complete=rep(0,6)
for (i in 1:15)
{memb4<-cutree(hc4,k=i)
complete[i]=dunn(d.norm,memb4)}

centroid=rep(0,6)
for (i in 1:15)
{memb5<-cutree(hc5,k=i)
centroid[i]=dunn(d.norm,memb5)}

ward.D=rep(0,15)
for (i in 1:15)
{memb6<-cutree(hc6,k=i)
ward.D[i]=dunn(d.norm,memb6)}

library(knitr)
dun<-data.frame(single,average,median,complete,centroid,ward.D) %>%round(2) 
k<-(1:15)
dunn_result<-cbind(k,dun)
library(writexl)
write_xlsx(x = dunn_result, path = "dunn_result.xlsx", col_names = TRUE)
```

####plot the histogram of clusters to decide the k
```{r}
# ward clusters are more evenly 


for (i in 1:3)
{memb2<-cutree(hc2,k=i)
hist(memb2)}

memb2<-cutree(hc2,k=2)
hist(memb2)

for (i in 1:3)
{memb4<-cutree(hc4,k=i)
hist(memb4)}

memb4<-cutree(hc4,k=2)
hist(memb4)

for (i in 1:3)
{memb6<-cutree(hc6,k=i)
hist(memb6)}

memb6<-cutree(hc6,k=2)
hist(memb6)

```


```{r}

# methods to assess
m <- c( "average",  "complete", "ward")
names(m) <- c( "average",  "complete", "ward")

# function to compute coefficient
ac <- function(x) {
  agnes(diabetes_hclust.df.norm, method = x)$ac
}

map_dbl(m, ac)

```


```{r}
# hcw <- agnes(dhclust.norm, method = "ward")
# 
# pltree(hcw, cex = 0.6, hang = -1, main = "Dendrogram of agnes")
```

```{r}
# Cut tree into 2 groups
# grouping <- cutree(hcw, k = 2)

diabetes_hclust$Outcome <- diabetes.copy$Outcome
diabetes_hclust$OutcomeClust <-memb6

#rename levels
diabetes_hclust$OutcomeClust <- gsub(2, 0, diabetes_hclust$OutcomeClust,ignore.case=T)

#change data types
diabetes_hclust$OutcomeClust <- as.factor(diabetes_hclust$OutcomeClust)
diabetes_hclust$Outcome <- as.factor(diabetes_hclust$Outcome)

#confusion Matrix
confusionMatrix(diabetes_hclust$Outcome, diabetes_hclust$OutcomeClust,positive = "1")
```

```{r}
# trees of method average, complete, ward.d are more clear, so we take those three
# different colors refer to different clusters
#head(colors()) 
# fviz_dend(hc2, k = 13, 
#           cex = 0.5, 
#           k_colors = c("#2E9FDF", "#00AFBB", "#E7B800", "#FC4E07", "#A52A2A","#FF4040","#EE3B3B","#8B2323","#CDAA7D","#98F5FF","#7FFF00","#66CD00","#53868B"),
#           color_labels_by_k = TRUE, 
#           rect = TRUE          
# )
# 
# fviz_dend(hc4, k = 8, 
#           cex = 0.5, 
#           k_colors = c("#2E9FDF", "#00AFBB", "#E7B800", "#FC4E07", "#A52A2A","#FF4040","#EE3B3B","#8B2323"),
#           color_labels_by_k = TRUE, 
#           rect = TRUE          
# )

fviz_dend(hc6, k = 2, 
          cex = 0.5, 
          k_colors = c("#2E9FDF", "#00AFBB"),
          color_labels_by_k = TRUE, 
          rect = TRUE          
)

# fviz_dend(hcw, k = 2,
#           cex = 0.5,
#           k_colors = c("#2E9FDF","#53868B"),
#           color_labels_by_k = TRUE,
#           rect = TRUE)
# 
# fviz_dend(hc4, k = 8,
#           cex = 0.5,
#           k_colors = c("#2E9FDF", "#00AFBB", "#E7B800", "#FC4E07", "#A52A2A","#FF4040","#EE3B3B","#8B2323"),
#           color_labels_by_k = TRUE,
#           rect = TRUE)
# 
# fviz_dend(hc6, k = 10,
#           cex = 0.5,
#           k_colors = c("#2E9FDF", "#00AFBB", "#E7B800", "#FC4E07", "#A52A2A","#FF4040","#EE3B3B","#8B2323","#66CD00","#53868B"),
#           color_labels_by_k = TRUE,
#           rect = TRUE)

```


```{r}
#get histogram for clusters
cat(memb2)
cat(memb4)
cat(memb6)

hist(average)
hist(complete)
hist(Ward)
```

```{r}
# get heatmaps for three methods

row.names(diabetes.df.norm) <- paste(memb2, ": ", row.names(diabetes), sep = "")

# set labels as cluster membership number : utility name
row.names(diabetes_hclust.df.norm) <- paste(average, ": ", row.names(diabetes_hclust), sep = "")


# plot heatmap 
# rev() reverses the color mapping to large = dark
heatmap(as.matrix(diabetes_hclust.df.norm), Colv = NA, hclustfun = hclust, 
        col=rev(paste("grey",1:99,sep="")))

# set labels as cluster membership number : utility name
row.names(diabetes_hclust.df.norm) <- paste(complete, ": ", row.names(diabetes_hclust), sep = "")

# plot heatmap 
# rev() reverses the color mapping to large = dark
heatmap(as.matrix(diabetes_hclust.df.norm), Colv = NA, hclustfun = hclust, 
        col=rev(paste("grey",1:99,sep="")))

# set labels as cluster membership number : utility name
row.names(diabetes_hclust.df.norm) <- paste(Ward, ": ", row.names(diabetes_hclust), sep = "")

# plot heatmap 
# rev() reverses the color mapping to large = dark
heatmap(as.matrix(diabetes_hclust.df.norm), Colv = NA, hclustfun = hclust, 
        col=rev(paste("grey",1:99,sep="")))

```

```{r}
# new dataset with cluster results
diabetes_hclust <- diabetes_hclust %>% mutate(HierCluster=memb6)



# Create theme for plots
theme <- theme_test(base_family = "Times New Roman") + theme(plot.title = element_text(hjust = 0.5), 
         legend.position = "bottom", panel.grid.minor = element_blank(), axis.ticks.x = element_blank(),
         axis.ticks.y = element_blank(), panel.grid.major = element_blank())
```

```{r}
# get boxplot of glucose for different clusters with three methods
##Glucose
ggplot(diabetes_hclust, aes(x = as.factor(HierCluster), y = Glucose   )) +
  geom_boxplot(colour = "black") +
  theme + labs(title = "Distribution of Glucose by cluster ", x = "cluster", y = "Glucose")

#BMI
ggplot(diabetes_hclust, aes(x = as.factor(HierCluster), y = BMI   )) +
  geom_boxplot(colour = "black") +
  theme + labs(title = "Distribution of BMI by cluster ", x = "cluster", y = "BMI")

#age
ggplot(diabetes_hclust, aes(x = as.factor(HierCluster), y = Age  )) +
  geom_boxplot(colour = "black") +
  theme + labs(title = "Distribution of age by cluster ", x = "cluster", y = "Age")


#DiabetesPedigreeFunction
ggplot(diabetes_hclust, aes(x = as.factor(HierCluster), y = DiabetesPedigreeFunction  )) +
  geom_boxplot(colour = "black") +
  theme + labs(title = "Distribution of DiabetesPedigreeFunction by cluster ", x = "cluster", y = "DiabetesPedigreeFunction")


#BloodPressure
ggplot(diabetes_hclust, aes(x = as.factor(HierCluster), y = BloodPressure  )) +
  geom_boxplot(colour = "black") +
  theme + labs(title = "Distribution of BloodPressure by cluster ", x = "cluster", y = "BloodPressure")

#Insulin
ggplot(diabetes_hclust, aes(x = as.factor(HierCluster), y =Insulin  )) +
  geom_boxplot(colour = "black") +
  theme + labs(title = "Distribution of Insulin by cluster ", x = "cluster", y = "Insulin")

# ggplot(diabetes_hclust, aes(x = as.factor(HierCluster2), y = Glucose)) +
#   geom_boxplot(colour = "black") +
#   theme + labs(title = "Distribution of Glucose by cluster of complete method", x = "cluster", y = "Glucose")
# 
# ggplot(diabetes_hclust, aes(x = as.factor(HierCluster3), y = Glucose)) +
#   geom_boxplot(colour = "black") +
#   theme + labs(title = "Distribution of Glucose by cluster of ward method", x = "cluster", y = "Glucose")

cluster_outcome<-diabetes_hclust %>% group_by(HierCluster,Outcome) %>% summarise(n=n())
write_xlsx(cluster_outcome, path =  "cluster_outcome.xlsx",col_names = TRUE,
  format_headers = TRUE)

#Outcome ~ Glucose +  BMI + Age+DiabetesPedigreeFunction + BloodPressure 

```


```{r}
#plot BMI and glucose
ggplot(diabetes_hclust, aes(BMI, Glucose, col = factor(HierCluster))) + 
  geom_point(stat = "identity")+theme
```

<<<<<<< HEAD
```{r}
#plot Age and glucose
ggplot(diabetes_hclust, aes(Age, Glucose, col = factor(HierCluster))) + 
  geom_point(stat = "identity")+theme
```
```{r}
#DiabetesPedigreeFunction and glucose
ggplot(diabetes_hclust, aes(DiabetesPedigreeFunction, Glucose, col = factor(HierCluster))) + 
  geom_point(stat = "identity")+theme
```


```{r}
#plot insulin and glucose
ggplot(diabetes_hclust, aes(Insulin, Glucose, col = factor(HierCluster))) + 
  geom_point(stat = "identity")+theme
```


```{r}
#plot BloodPressure and glucose
ggplot(diabetes_hclust, aes(BloodPressure, Glucose, col = factor(HierCluster))) + 
  geom_point(stat = "identity")+theme

#######################################################################################

### 3. Improvement of Models

##### Clustering Selection

(1) average
```{r}
data <- diabetes.copy
data$KMeansCluster <- dia.k2$cluster
data$HierCluster <- average

# CHANGE DATA TYPE
data$Outcome <- as.factor(data$Outcome)
data$Pregnancies <- as.factor(data$Pregnancies)

# divide data into train and test set
set.seed(1)
randOrder = order(runif(nrow(data)))
train.df = subset(data,randOrder < .8 * nrow(data))
test.df = subset(data,randOrder > .8 * nrow(data))
```

(2) complete
```{r}
data2 <- diabetes.copy
data2$KMeansCluster <- dia.k2$cluster
data2$HierCluster <- complete

# CHANGE DATA TYPE
data2$Outcome <- as.factor(data$Outcome)
data2$Pregnancies <- as.factor(data$Pregnancies)

# divide data into train and test set
set.seed(1)
randOrder = order(runif(nrow(data2)))
train.df2 = subset(data2,randOrder < .8 * nrow(data2))
test.df2 = subset(data2,randOrder > .8 * nrow(data2))
```

(3) Ward
```{r}
data3 <- diabetes.copy
data3$KMeansCluster <- dia.k2$cluster
data3$HierCluster <- Ward

# CHANGE DATA TYPE
data3$Outcome <- as.factor(data$Outcome)
data3$Pregnancies <- as.factor(data$Pregnancies)

# divide data into train and test set
set.seed(1)
randOrder = order(runif(nrow(data3)))
train.df3 = subset(data3,randOrder < .8 * nrow(data3))
test.df3 = subset(data3,randOrder > .8 * nrow(data3))
```

##### correlation matrix

```{r, fig.width=8}
# plot the correlation matrix visual
par(mfrow=c(1,3))

### average
corr.df <- train.df
corr.df$Outcome <- as.numeric(corr.df$Outcome)
corr.df$Pregnancies <- as.numeric(corr.df$Pregnancies)
cor <- cor(corr.df)
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot1 <- corrplot(cor, method="color", col=col(200),  
         type="upper", order="hclust", 
         addCoef.col = "black", # Add coefficient of correlation
         tl.col="black", tl.srt=45, #Text label color and rotation
         # Combine with significance
         sig.level = 0.01, insig = "blank", 
         # hide correlation coefficient on the principal diagonal
         diag=FALSE, title = "average"
         )
### complete
corr.df <- train.df2
corr.df$Outcome <- as.numeric(corr.df$Outcome)
corr.df$Pregnancies <- as.numeric(corr.df$Pregnancies)
cor <- cor(corr.df)
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot2 <- corrplot(cor, method="color", col=col(200),  
         type="upper", order="hclust", 
         addCoef.col = "black", # Add coefficient of correlation
         tl.col="black", tl.srt=45, #Text label color and rotation
         # Combine with significance
         sig.level = 0.01, insig = "blank", 
         # hide correlation coefficient on the principal diagonal
         diag=FALSE, title = "complete"
         )
### Ward
corr.df <- train.df3
corr.df$Outcome <- as.numeric(corr.df$Outcome)
corr.df$Pregnancies <- as.numeric(corr.df$Pregnancies)
cor <- cor(corr.df)
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot3 <- corrplot(cor, method="color", col=col(200),  
         type="upper", order="hclust", 
         addCoef.col = "black", # Add coefficient of correlation
         tl.col="black", tl.srt=45, #Text label color and rotation
         # Combine with significance
         sig.level = 0.01, insig = "blank", 
         # hide correlation coefficient on the principal diagonal
         diag=FALSE, title = "Ward"
         )
```

```{r}
# create model with no predictors for bottom of search range
glu.lm.null <- lm(Glucose ~1, data = train.df2)
glu.lm <- lm(Glucose ~., data = train.df2)

# backward
glu.lm.step_back <- step(glu.lm, direction = "backward")
sum_back <- summary(glu.lm.step_back) 
summary(glu.lm.step_back) 
```

```{r}
# create model with no predictors for bottom of search range
glu.lm.null <- lm(Glucose ~1, data = train.df3)
glu.lm <- lm(Glucose ~., data = train.df3)

# backward
glu.lm.step_back <- step(glu.lm, direction = "backward")
sum_back <- summary(glu.lm.step_back) 
summary(glu.lm.step_back) 
```

```{r}
# create model with no predictors for bottom of search range
glu.lm.null <- lm(Glucose ~1, data = train.df)
glu.lm <- lm(Glucose ~., data = train.df)

# backward
glu.lm.step_back <- step(glu.lm, direction = "backward")
sum_back <- summary(glu.lm.step_back) 
summary(glu.lm.step_back) 
```

#### the best model for predict glucose
Glucose ~ DiabetesPedigreeFunction + BloodPressur + newInsu
```{r}
#  use options() to ensure numbers are not displayed in scientific notation.
options(scipen = 999)
Glucose_model <- lm(formula = Glucose ~ BMI + DiabetesPedigreeFunction + Age + 
                              Outcome + Insulin + KMeansCluster + HierCluster, data = train.df)
summary(Glucose_model)  # r^2 = 0.3417
RMSE <- round(sqrt(c(crossprod(Glucose_model$residuals)) / length(Glucose_model$residuals)),2)
RMSE

#check for Variance Inflation Factor (VIF); must be < 10; should be less than 5
vif(Glucose_model)

## additional diagnostics to checsk for outliers/leverage points
par(mfrow=c(2,2))
plot(Glucose_model, cex=0.5)

# remove outliers
train.df3 <- train.df2[-c(183, 61, 400, 211, 48),]

# use accuracy() to compute common accuracy measures. # rmse 25.26732
accuracy(predict(Glucose_model,train.df3), train.df3$Glucose) %>% kable()
```

#### Validation
```{r}
#### Table 6.4
# use predict() to make predictions on a new set. 
glu.lm.pred <- predict(glu.lm, test.df)
options(scipen=999, digits = 0)
residuals <- test.df$Glucose - glu.lm.pred
result_glu<-data.frame("Predicted" = glu.lm.pred, "Actual" = test.df$Glucose,
           "Residual" = residuals)

options(scipen=999, digits = 3)
# use accuracy() to compute common accuracy measures.
accuracy(glu.lm.pred, test.df$Glucose) %>% kable()
```

```{r, fig.width=2}
## histogram for residuals
a<-data.frame(Glucose_model$residuals)
# Histogram with density plot
# Add mean line
p2<-ggplot(a, aes(x=Glucose_model.residuals)) + 
 geom_histogram(aes(y=..density..), colour="black", fill="white")+
 geom_density(alpha=.2, fill="#FF6666")+
  geom_vline(aes(xintercept=mean(Glucose_model.residuals)),
            color="red", linetype="dashed", size=1) +
  theme
p2

```
